{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOArUmUBrABct/IVe1N0RV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gennadiy-Korobeynikov/iris_classification_interactive/blob/main/iris_classification_interactive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn import datasets\n",
        "from sklearn import model_selection # for split\n",
        "\n",
        "def sigmoid(z):\n",
        "    \"\"\"The sigmoid function.\n",
        "    Сигмоида\n",
        "    \"\"\"\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    \"\"\"Derivative of the sigmoid function.\n",
        "    Производная сигмоиды по e (шутка). По x\n",
        "    \"\"\"\n",
        "    return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "def cost_function(network, test_data, onehot=True):\n",
        "    c = 0\n",
        "    for example, y in test_data:\n",
        "        if not onehot:\n",
        "            y = np.eye(3, 1, k=-int(y))\n",
        "        yhat = network.feedforward(example)\n",
        "        c += np.sum((y - yhat)**2)\n",
        "    return c / len(test_data)"
      ],
      "metadata": {
        "id": "f1JAjGMF1Mpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JExDj4HdxYWB"
      },
      "outputs": [],
      "source": [
        "class Network:\n",
        "\n",
        "    def __init__(self, sizes, output=True):\n",
        "\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "        self.weights = [np.random.randn(y, x)\n",
        "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "        self.output = output\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
        "            test_data=None):\n",
        "\n",
        "\n",
        "        if test_data is not None: n_test = len(test_data)\n",
        "        n = len(training_data)\n",
        "        success_tests = 0\n",
        "        for j in range(epochs):\n",
        "            random.shuffle(training_data)\n",
        "            mini_batches = [\n",
        "                training_data[k:k+mini_batch_size]\n",
        "                for k in range(0, n, mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, eta)\n",
        "            #if test_data is not None and self.output:\n",
        "                #success_tests = self.evaluate(test_data)\n",
        "                #print(\"Эпоха {0}: {1} / {2}\".format(\n",
        "                #    j, success_tests, n_test))\n",
        "         #   elif self.output:\n",
        "          #      print(\"Эпоха {0} завершена\".format(j))\n",
        "        if test_data is not None:\n",
        "            return self.evaluate(test_data) / n_test\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, eta):\n",
        "\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "\n",
        "        eps = eta / len(mini_batch)\n",
        "        self.weights = [w - eps * nw for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases  = [b - eps * nb for b, nb in zip(self.biases,  nabla_b)]\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "        # прямое распространение (forward pass)\n",
        "        a = x\n",
        "        self.ass = [x]\n",
        "        self.zs = []\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = w@a+b\n",
        "            self.zs.append(z)\n",
        "            a = sigmoid(z)\n",
        "            self.ass.append(a)\n",
        "\n",
        "        # обратное распространение (backward pass)\n",
        "        delta = (a-y)*(sigmoid_prime(self.zs[-1])) # ошибка выходного слоя\n",
        "        nabla_b[-1] = delta # производная J по смещениям выходного слоя\n",
        "        nabla_w[-1] = delta@(self.ass[-2].T)# производная J по весам выходного слоя\n",
        "\n",
        "        # Здесь l = 1 означает последний слой,\n",
        "        # l = 2 - предпоследний и так далее.\n",
        "        for l in range(2, self.num_layers):\n",
        "            delta = ( (self.weights[-l+1].T)@delta)*sigmoid_prime(self.zs[-l]) # ошибка на слое L-l\n",
        "            nabla_b[-l] = delta # производная J по смещениям L-l-го слоя\n",
        "            nabla_w[-l] = delta@(self.ass[-l-1].T)  # производная J по весам L-l-го слоя\n",
        "        return nabla_b, nabla_w\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        return (output_activations-y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.20)\n",
        "y_train = y_train[:, np.newaxis]\n",
        "y_test = y_test[:, np.newaxis]\n",
        "train = np.hstack([x_train, y_train])\n",
        "test = np.hstack([x_test, y_test])\n",
        "train = [(d[:input_count][:, np.newaxis], np.eye(3, 1, k=-int(d[-1]))) for d in train]\n",
        "test =  [(d[:input_count][:, np.newaxis], d[-1]) for d in test]"
      ],
      "metadata": {
        "id": "XpoYBQLm1hZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_count  = 4\n",
        "hidden_count = 6\n",
        "output_count = 3\n",
        "\n",
        "r = np.array([])\n",
        "for i in range(10):\n",
        "  nn = Network([input_count, hidden_count, output_count])\n",
        "  r=   np.append( r,nn.SGD(training_data=train, epochs=500, mini_batch_size=10, eta=0.05, test_data=test))\n",
        "print(np.mean(r))"
      ],
      "metadata": {
        "id": "k_V6pSWckngC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3da151-4e5e-417f-e839-0a35b3e321d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9566666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import *\n",
        "@interact(layer1=IntSlider(min=0, max=10, continuous_update=False, description=\"1й внутренний слой: \", value=6),\n",
        "          layer2=IntSlider(min=0, max=10, continuous_update=False, description=\"2й внутренний слой:\"),\n",
        "          layer3=IntSlider(min=0, max=10, continuous_update=False, description=\"3й внутренний слой: \"),\n",
        "          batch_size=BoundedIntText(min=1, max=40, value=10, description=\"Batch size: \"),\n",
        "          learning_rate=Dropdown(options=[\"0.01\", \"0.05\", \"0.1\", \"0.5\", \"1\", \"5\", \"10\"],\n",
        "                                 description=\"Learning rate: \")\n",
        "         )\n",
        "def learning_curve_by_network_structure(layer1, layer2, layer3, batch_size, learning_rate):\n",
        "    layers = [x for x in [input_count, layer1, layer2, layer3, output_count] if x > 0]\n",
        "    nn = Network(layers, output=False)\n",
        "    learning_rate=float(learning_rate)\n",
        "\n",
        "    CER = []\n",
        "    cost_train = []\n",
        "    cost_test  = []\n",
        "    for _ in range(500):\n",
        "        nn.SGD(training_data=train, epochs=1, mini_batch_size=batch_size, eta=learning_rate)\n",
        "        CER.append(1 - nn.evaluate(test) / len(test))\n",
        "        cost_test.append(cost_function(nn, test, onehot=False))\n",
        "        cost_train.append(cost_function(nn, train, onehot=True))\n",
        "\n",
        "    fig = plt.figure(figsize=(15,5))\n",
        "    fig.add_subplot(1,2,1)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.plot(CER)\n",
        "    plt.title(\"Ошибка классификации\")\n",
        "    plt.ylabel(\"Доля неверно классифицированных объектов\")\n",
        "    plt.xlabel(\"Количество эпох\")\n",
        "\n",
        "    fig.add_subplot(1,2,2)\n",
        "    plt.plot(cost_train, label=\"Отклонение при обучении\", color=\"orange\")\n",
        "    plt.plot(cost_test, label=\"Отклонение при тестировании\", color=\"blue\")\n",
        "    plt.title(\"Кривая обучения\")\n",
        "    plt.ylabel(\"Функция потерь\")\n",
        "    plt.xlabel(\"Количество эпох\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "f9074f43d96c4155a8fbbfac633f759e",
            "661d58bad3d84274a260b14ad8843439",
            "202e438a8d30436b8e8936a5e4201007",
            "ad31a7f973814f79befe4d6b2a4888b0",
            "3619395422e3462f962090d00084390a",
            "262701cdf9824a67b6129f56e1ec3579",
            "0e0545bca8004166826fe4da5f0ea007",
            "108f17b84e2344e9b6577a64718f0e4c",
            "6c5ca123dd2843f192058565254ae652",
            "f1e416f15c364162b9f9e005e2aeaf70",
            "9515c925e99a4333bdcf285a15214d33",
            "0bf8c43c702d40958fa53e1ff2fd76f2",
            "9c19c44a22e74138b1513d7a3c835678",
            "cd0f899a57a64000a58af7cdb5341fd9",
            "d691d92ca936461fbf980bfa669cedcb",
            "d987b0bfd7c743ba9aea4dc6e899d4dc",
            "ce9e51650ad3463ea2a57b7851ac8940",
            "99a8fc08749146ffa6e3cde915c5032e",
            "3964cef4d8ab4c3291aa79ffa62b8102"
          ]
        },
        "id": "7J9JfTWC98To",
        "outputId": "38eeb9b2-bc1c-48ee-f272-782403b082bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=6, continuous_update=False, description='1й внутренний слой: ', max=10),…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9074f43d96c4155a8fbbfac633f759e"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}
